{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gBjOO4luVO6u",
    "outputId": "9bbe2c27-9957-4c57-a31c-972a82ce6d39"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TTKpmxYqXoyI",
    "outputId": "105e2850-0515-4883-b1e7-6edc5084498b"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k33vOPT2aCDn"
   },
   "outputs": [],
   "source": [
    "!mkdir -p data\n",
    "!cp -r /gdrive/MyDrive/tutorial_nlp/chap2/data/* ./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "grdhWuTtY0M6"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "random_state= 42\n",
    "torch.manual_seed(1)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t8YJaCiimubB"
   },
   "source": [
    "### Dataset\n",
    "- [x] Vocab class\n",
    "  - [x] for source language\n",
    "    - [x] 入力言語の語彙数: 2698\n",
    "  - [x] for destination language\n",
    "    - [x] 出力言語の語彙数: 3051\n",
    "- [x] split dataset for training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Um_P6t6fF5GW",
    "outputId": "2b3ff72c-d9ba-4086-8282-d64db5d05200"
   },
   "outputs": [],
   "source": [
    "!head -5 ./data/train.en\n",
    "!head -5 ./data/train.ja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UJkNRcagHS7u"
   },
   "outputs": [],
   "source": [
    "PAD_TOKEN = '<PAD>'\n",
    "UNK_TOKEN = '<UNK>'\n",
    "BOS_TOKEN = '<S>'\n",
    "EOS_TOKEN = '</S>'\n",
    "PAD = 0\n",
    "UNK = 1\n",
    "BOS = 2\n",
    "EOS = 3\n",
    "\n",
    "word2id = {\n",
    "    PAD_TOKEN: PAD,\n",
    "    UNK_TOKEN: UNK,\n",
    "    BOS_TOKEN: BOS,\n",
    "    EOS_TOKEN: EOS,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QJs2IIpHIt2i"
   },
   "outputs": [],
   "source": [
    "def load_data(filepath):\n",
    "    sentences = []\n",
    "    with open(filepath, 'r', encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            sentence = line.strip('\\n').strip().split()\n",
    "            sentences.append(sentence)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "def sentence_to_ids(vocab, sentence):\n",
    "    _ids = [vocab.word2id.get(word, UNK) for word in sentence]\n",
    "    _ids += [EOS]\n",
    "    return _ids\n",
    "\n",
    "\n",
    "def pad_seq(seq, max_len):\n",
    "    padded = seq + [PAD for _ in range(max_len - len(seq))]\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-OM_hqGFHqS7"
   },
   "outputs": [],
   "source": [
    "class Vocab(object):\n",
    "    def __init__(self, word2id={}):\n",
    "        self.word2id = dict(word2id)\n",
    "        self.id2word = {id: word for word, id in self.word2id.items()}\n",
    "\n",
    "    def build_vocab(self, sentences, min_count=1):\n",
    "        word_counter = defaultdict(int)\n",
    "        for sentence in sentences:\n",
    "            for word in sentence:\n",
    "                word_counter[word] = word_counter.get(word, 0) + 1\n",
    "\n",
    "        for word, count in sorted(word_counter.items(), key=lambda x: x[1], reverse=True):\n",
    "            if count >= min_count:\n",
    "                _id = len(self.word2id)\n",
    "                self.word2id.setdefault(word, _id)\n",
    "                self.id2word[_id] = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CE_d7mWHIL7j",
    "outputId": "2681897a-fae5-44f9-834f-ddd7b05bbdb3"
   },
   "outputs": [],
   "source": [
    "# 動作確認\n",
    "train_X = load_data('./data/train.en')\n",
    "train_Y = load_data('./data/train.ja')\n",
    "train_X = train_X[:len(train_X) // 2]\n",
    "train_Y = train_Y[:len(train_Y) // 2]\n",
    "train_X, valid_X, train_Y, valid_Y = train_test_split(train_X, train_Y, test_size=0.2, random_state=random_state)\n",
    "\n",
    "vocab_X = Vocab(word2id)\n",
    "vocab_X.build_vocab(train_X, min_count=2)\n",
    "vocab_Y = Vocab(word2id)\n",
    "vocab_Y.build_vocab(train_Y, min_count=2)\n",
    "\n",
    "vocab_size_X = len(vocab_X.id2word)\n",
    "vocab_size_Y = len(vocab_Y.id2word)\n",
    "print('入力言語の語彙数：', vocab_size_X)\n",
    "print('出力言語の語彙数：', vocab_size_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "usLHbQ64O5nF"
   },
   "outputs": [],
   "source": [
    "train_X = [sentence_to_ids(vocab_X, sentence) for sentence in train_X]\n",
    "valid_X = [sentence_to_ids(vocab_X, sentence) for sentence in valid_X]\n",
    "train_Y = [sentence_to_ids(vocab_Y, sentence) for sentence in train_Y]\n",
    "valid_Y = [sentence_to_ids(vocab_Y, sentence) for sentence in valid_Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pUgeIv4jNNG2",
    "outputId": "50836900-12f3-46d2-f494-21d9dfba22fe"
   },
   "outputs": [],
   "source": [
    "# 動作確認\n",
    "\"\"\"\n",
    "train_X[0]\n",
    ">>> [18, 86, 9, 52, 342, 32, 22, 4, 2]\n",
    "EOS = 3 にしているので、\n",
    ">>> [18, 86, 9, 52, 342, 32, 22, 4, 3]\n",
    "\"\"\"\n",
    "train_X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j9c4F-GVG1dT"
   },
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Ky812XXG3Y-"
   },
   "outputs": [],
   "source": [
    "class DataLoader(object):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        :param X: list, 入力言語の文章（単語IDのリスト）のリスト\n",
    "        :param Y: list, 出力言語の文章（単語IDのリスト）のリスト\n",
    "        :param batch_size: int, バッチサイズ\n",
    "        :param shuffle: bool, サンプルの順番をシャッフルするか否か\n",
    "        \"\"\"\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def reset(self):\n",
    "        # サンプルの順番をシャッフルする\n",
    "        # ポインタの位置を初期化する\n",
    "        pass\n",
    "\n",
    "    def __next__(self):\n",
    "        # ポインタが最後まで到達したら初期化する\n",
    "\n",
    "        # バッチを取得\n",
    "\n",
    "        # 入力系列seqs_Xの文章の長さ順（降順）に系列ペアをソートする\n",
    "\n",
    "        # 短い系列の末尾をパディングする\n",
    "\n",
    "        # tensorに変換し、転置する\n",
    "\n",
    "        # ポインタを更新する\n",
    "\n",
    "        return batch_X, batch_Y, lengths_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sq7hWY4SG3qe"
   },
   "source": [
    "### Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ok4J5N8sG5tG"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "\n",
    "class EncoderDecoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EncoderDecoder, self).__init__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jYRjPr8wG50P"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219
    },
    "id": "pBG4H5e_G69K",
    "outputId": "9a650dad-2923-4d1d-8665-16b0e3fa5aa4"
   },
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "num_epochs = 10\n",
    "batch_size = 64\n",
    "lr = 1e-3\n",
    "teacher_forcing_rate = 0.2\n",
    "ckpt_path = 'model.pth'\n",
    "\n",
    "model_args = {\n",
    "    'input_size': vocab_size_X,\n",
    "    'output_size': vocab_size_Y,\n",
    "    'hidden_size': 256,\n",
    "}\n",
    "\n",
    "train_dataloader = None\n",
    "valid_dataloader = None\n",
    "model = EncoderDecoder(**model_args).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xCzFF_jBQbC1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rz338gIOQxKJ"
   },
   "source": [
    "### Validation\n",
    "- [ ] Epoch 10 Train/Loss ... BLEU ... Valid/Loss ~42 BLEU ~13 程度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SWU0NoKgQyDD"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "lecture_chap2_exercise.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
