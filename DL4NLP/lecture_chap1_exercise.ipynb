{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gBjOO4luVO6u",
    "outputId": "14418a74-0f84-4ac8-80f0-51fe347dcf22"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aWUErmrZV1pL",
    "outputId": "5ab4c61b-56dc-46c2-db53-81cb7b19bdd6"
   },
   "outputs": [],
   "source": [
    "# !wget \"https://drive.google.com/uc?export=download&id=1SfrBnDt7-PrFL8zjfVap-FOPoUS6dqcT\" -O data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TTKpmxYqXoyI",
    "outputId": "a631de26-fd76-485d-d455-53812dd5dc63"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xMYToEEdYed4",
    "outputId": "35e0b266-bf59-4d37-d166-bab470856061"
   },
   "outputs": [],
   "source": [
    "!ls /gdrive/MyDrive/tutorial_nlp/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zkeVUF1RYo0R"
   },
   "outputs": [],
   "source": [
    "!apt-get -q -y install swig \n",
    "!apt-get install mecab\n",
    "!apt-get install libmecab-dev\n",
    "!apt-get install mecab-ipadic-utf8\n",
    "!pip install mecab-python3==0.996.5\n",
    "!pip install unidic-lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "grdhWuTtY0M6"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import time\n",
    "\n",
    "import MeCab\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GzDWtOheZHDw"
   },
   "outputs": [],
   "source": [
    "tagger = MeCab.Tagger('-Ochasen')\n",
    "node = tagger.parse('坊主が屏風に上手に坊主の絵を描いた')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ACY0Rpp3ZRhR",
    "outputId": "3ced2873-8f51-4752-96ae-eff063bc232b"
   },
   "outputs": [],
   "source": [
    "print(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ULrH3o9aZR3F"
   },
   "outputs": [],
   "source": [
    "def tokenize(sentence):\n",
    "    node = tagger.parse(sentence)\n",
    "    node = node.split('\\n')\n",
    "    tokenized_sentence = []\n",
    "    for i in range(len(node)):\n",
    "        feature = node[i].split('\\t')\n",
    "        if feature[0] == 'EOS':\n",
    "            break\n",
    "        tokenized_sentence.append(feature[0])\n",
    "    return tokenized_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iLiv5zb9ZsZl",
    "outputId": "ed23b1c4-d01b-480a-a13b-01a102462b5e"
   },
   "outputs": [],
   "source": [
    "tokenize(('坊主が屏風に上手に坊主の絵を描いた'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k33vOPT2aCDn"
   },
   "outputs": [],
   "source": [
    "!mkdir -p data\n",
    "!cp -r /gdrive/MyDrive/tutorial_nlp/data/* ./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sajVGKBSaMQf",
    "outputId": "4b10d823-10cc-4d8e-eb79-6e60dea31fec"
   },
   "outputs": [],
   "source": [
    "!ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BeWYiQBZaM_p",
    "outputId": "734d7bff-9551-42c4-d321-1db5df691c1e"
   },
   "outputs": [],
   "source": [
    "!head -5 ./data/kokoro.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uf4aUj28aRyh"
   },
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    text = []\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            line = tokenize(line)\n",
    "            text.append(line)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3hwhkBEuaar7"
   },
   "outputs": [],
   "source": [
    "text = load_data('./data/kokoro.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z2nmyZ-tao99",
    "outputId": "9a6d7d76-a00d-4d18-a9ad-368cf5943368"
   },
   "outputs": [],
   "source": [
    "print(text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WA-vv1XNaqeZ"
   },
   "outputs": [],
   "source": [
    "PAD_TOKEN = '<PAD>'\n",
    "UNK_TOKEN = '<UNK>'\n",
    "PAD = 0\n",
    "UNK = 1\n",
    "MIN_COUNT = 1\n",
    "\n",
    "word2id = {\n",
    "    PAD_TOKEN: PAD,\n",
    "    UNK_TOKEN: UNK,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yk9YT-I4a6Jh"
   },
   "outputs": [],
   "source": [
    "class Vocab(object):\n",
    "    def __init__(self, word2id={}):\n",
    "        self.word2id = word2id\n",
    "        self.id2word = {id: word for word, id in word2id.items()}\n",
    "\n",
    "    def build_vocab(self, sentences, min_count=1):\n",
    "        # count words in the corpus\n",
    "        word_counter = defaultdict(int)\n",
    "        for sentence in sentences:\n",
    "            for word in sentence:\n",
    "                word_counter[word] = word_counter.get(word, 0) + 1\n",
    "\n",
    "        # add to vocabs the word whose count >= min_count\n",
    "        words = sorted([(word, count) for word, count in word_counter.items()], key=lambda x: x[1], reverse=True)\n",
    "        for word, count in words:\n",
    "            if count >= min_count:\n",
    "                _id = len(self.word2id)\n",
    "                self.word2id.setdefault(word, _id)\n",
    "                self.id2word[_id] = word\n",
    "\n",
    "        self.raw_vocab = {w: word_counter[w] for w in self.word2id if w in word_counter}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gzuzWqxgbTQ1"
   },
   "outputs": [],
   "source": [
    "vocab = Vocab(word2id)\n",
    "vocab.build_vocab(text, min_count=MIN_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UaunaodBeVFi",
    "outputId": "2d8975a5-f478-42d5-a203-a1073cd1206b"
   },
   "outputs": [],
   "source": [
    "print(len(vocab.word2id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g1eUcEDseaim"
   },
   "outputs": [],
   "source": [
    "def sentence_to_ids(vocab, sen):\n",
    "    out = [vocab.word2id.get(word, UNK) for word in sen]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0aBCQyZlebUk"
   },
   "outputs": [],
   "source": [
    "id_text = [sentence_to_ids(vocab, sen) for sen in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S1KROR7OebZg",
    "outputId": "d1512e60-2410-46ef-f89d-9e085d769ce2"
   },
   "outputs": [],
   "source": [
    "print(text[0])\n",
    "print(id_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fayt0-eiebcD"
   },
   "outputs": [],
   "source": [
    "def pad_seq(seq, max_length):\n",
    "    \"\"\"Paddingを行う関数\n",
    "\n",
    "    :param seq: list of int, 単語のインデックスのリスト\n",
    "    :param max_length: int, バッチ内の系列の最大長\n",
    "    :return seq: list of int, 単語のインデックスのリスト\n",
    "    \"\"\"\n",
    "    seq += [PAD for _ in range(max_length - len(seq))]\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kKzhGrujohCq"
   },
   "source": [
    "### CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jQL5vw-QfCOr"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "n_batches = 500\n",
    "vocab_size = len(vocab.word2id)\n",
    "embedding_size = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RQsHGhEMfCUL"
   },
   "outputs": [],
   "source": [
    "class CBOWDataLoader(object):\n",
    "    def __init__(self, text, batch_size, window=3):\n",
    "        \"\"\"\n",
    "        :param text: list of list of int, 単語をIDに変換したデータセット\n",
    "        :param batch_size: int, ミニバッチのサイズ\n",
    "        :param window: int, 周辺単語とターゲットの単語の最大距離\n",
    "        \"\"\"\n",
    "        self.text = text\n",
    "        self.batch_size = batch_size\n",
    "        self.window = window\n",
    "        self.s_pointer = 0\n",
    "        self.max_s_pointer = len(self.text)\n",
    "        self.w_pointer = 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        batch_X, batch_Y = [], []\n",
    "\n",
    "        while len(batch_X) < self.batch_size:\n",
    "            assert len(batch_X) == len(batch_Y)\n",
    "            # 走査する対象の文\n",
    "            sen = self.text[self.s_pointer]\n",
    "            # 予測すべき単語\n",
    "            word_Y = sen[self.w_pointer]\n",
    "            # 入力となる単語群を取得\n",
    "            words_X = sen[max(0, self.w_pointer - self.window):self.w_pointer] + sen[self.w_pointer + 1:self.w_pointer + 1 + self.window]\n",
    "            words_X = pad_seq(words_X, self.window * 2)\n",
    "            batch_X.append(words_X)\n",
    "            batch_Y.append(word_Y)\n",
    "            self.w_pointer += 1\n",
    "            # 文を走査し終わったら次の文の先頭にポインタを移行する\n",
    "            # 全ての文を走査し終わったら終了する\n",
    "            if self.w_pointer >= len(sen):\n",
    "                self.s_pointer += 1\n",
    "                self.w_pointer = 0\n",
    "                if self.s_pointer >= self.max_s_pointer:\n",
    "                    self.s_pointer = 0\n",
    "                    raise StopIteration\n",
    "\n",
    "        # データはtorch.Tensorにする必要があります。dtype, deviceも指定します。\n",
    "        batch_X = torch.tensor(batch_X, dtype=torch.long, device=device)\n",
    "        batch_Y = torch.tensor(batch_Y, dtype=torch.long, device=device)\n",
    "\n",
    "        return batch_X, batch_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "43WrSjSOfsta"
   },
   "outputs": [],
   "source": [
    "class CBOW(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size):\n",
    "        \"\"\"\n",
    "        :param vocab_size: int, 語彙の総数\n",
    "        :param embedding_size: int, 単語埋め込みベクトルの次元\n",
    "        \"\"\"\n",
    "        super(CBOW, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_size = embedding_size\n",
    "\n",
    "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_size)\n",
    "        # 全結合層(バイアスなし)\n",
    "        self.linear = nn.Linear(self.embedding_size, self.vocab_size, bias=False)\n",
    "\n",
    "    def forward(self, batch_X, batch_Y):\n",
    "        \"\"\"\n",
    "        :param batch_X: torch.Tensor(dtype=torch.long), (batch_size, window*2)\n",
    "        :param batch_Y: torch.Tensor(dtype=torch.long), (batch_size,)\n",
    "        :return loss: torch.Tensor(dtype=torch.float), CBOWのloss\n",
    "        \"\"\"\n",
    "        # (batch_size, window*2, embedding_size)\n",
    "        x = self.embedding(batch_X)\n",
    "        # paddingした部分を無視するためにマスクをかけます\n",
    "        # (batch_size, window*2, embedding_size)\n",
    "        x = x * (batch_X != PAD).float().unsqueeze(-1)\n",
    "        # (batch_size, embedding_size)\n",
    "        x = x.sum(dim=1)\n",
    "        # (batch_size, vocab_size)\n",
    "        x = self.linear(x)\n",
    "        # (batch_size, vocab_size)\n",
    "        log_prob = F.log_softmax(x, dim=-1)\n",
    "        loss = F.nll_loss(log_prob, batch_Y)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d_-gOv6Yl8J6"
   },
   "source": [
    "### CBOW Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ay36DqghjeJ6"
   },
   "outputs": [],
   "source": [
    "cbow = CBOW(vocab_size, embedding_size).to(device)\n",
    "optimizer_cbow = optim.Adam(cbow.parameters())\n",
    "dataloader_cbow = CBOWDataLoader(id_text, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OYsjudbSjeMM"
   },
   "outputs": [],
   "source": [
    "def compute_loss(model, inputs, optimizer, is_train=True):\n",
    "    \"\"\"lossを計算するための関数\n",
    "    \n",
    "    is_train=Trueならモデルをtrainモードに、\n",
    "    is_train=Falseならモデルをevaluationモードに設定します\n",
    "    \n",
    "    :param model: 学習させるモデル\n",
    "    :param input: モデルへの入力\n",
    "    :param optimizer: optimizer\n",
    "    :param is_train: bool, モデルtrainさせるか否か\n",
    "    \"\"\"\n",
    "    model.train(is_train)\n",
    "    loss = model(*inputs)\n",
    "    if is_train:\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vwKnsrKwjeOU",
    "outputId": "36ae8116-9776-4ce9-cd32-1305609836be"
   },
   "outputs": [],
   "source": [
    "start_at = time.time()\n",
    "\n",
    "for batch_id, (batch_X, batch_Y) in enumerate(dataloader_cbow):\n",
    "    loss = compute_loss(cbow, [batch_X, batch_Y], optimizer_cbow, is_train=True)\n",
    "    if (batch_id + 1) % 100 == 0:\n",
    "        print(f'Time {time.time() - start_at:.2f} [sec] Loss {loss:.4f}')\n",
    "    if (batch_id + 1) >= n_batches:\n",
    "        break\n",
    "\n",
    "print('Training finished in {:.2f} [sec]'.format(time.time() - start_at))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r1W5bJPBpBvN"
   },
   "source": [
    "### Skipgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SBvdUnP0nB_T"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NXBue5xVnCBi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LvjSGggIfCWx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HbEAi7UOpZmz"
   },
   "source": [
    "### Word Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fwslPauuebfD"
   },
   "outputs": [],
   "source": [
    "def compute_word_similarity(embedding_path, word, n):\n",
    "    \"\"\"\n",
    "    与えられた単語に最も似ている単語とcos類似度を返す関数\n",
    "\n",
    "    :param embedding_path: str, 保存した埋め込み層のパラメータのパス\n",
    "    :param word: str, 単語\n",
    "    :param n: int\n",
    "    :return out: str, 上位n個の類似単語とそのcos類似度\n",
    "    \"\"\"\n",
    "    embedding = torch.load(embedding_path)\n",
    "\n",
    "    # 単語ベクトルを全て単位ベクトルにする\n",
    "    norm = np.linalg.norm(embedding, ord=2, axis=1, keepdims=True)\n",
    "    norm = np.where(norm == 0, 1, norm)\n",
    "    embedding /= norm\n",
    "    e = embedding[vocab.word2id[word]]\n",
    "\n",
    "    # 単語ベクトル同士のcos類似度を計算する\n",
    "    cos_sim = np.dot(embedding, e.reshape(-1, 1)).reshape(-1, )\n",
    "    most_sim = np.argsort(cos_sim, axis=-1)[::-1][1:n+1]\n",
    "    most_sim_words = [vocab.id2word[id] for id in most_sim]\n",
    "    top_cos_sim = cos_sim[most_sim]\n",
    "    out = ', '.join([w + f'({v:.4f})' for w, v in zip(most_sim_words, top_cos_sim)])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SDR7BwzMpo8F",
    "outputId": "fb6f5302-3c35-42a3-fa77-3d9db9783b9f"
   },
   "outputs": [],
   "source": [
    "# 500バッチだけ学習した時\n",
    "models = [\"cbow\", \"sg\", \"sgns\"]\n",
    "for model in models:\n",
    "    print(model+\"\\t:\", compute_word_similarity(\n",
    "        \"./data/\" + model + \"_embedding.pth\", \"私\", 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HymV8cxxsOhg",
    "outputId": "18153513-5b4a-4456-9852-1629a7408a5c"
   },
   "outputs": [],
   "source": [
    "# 1エポック学習した時\n",
    "models = [\"cbow\", \"sg\", \"sgns\"]\n",
    "for model in models:\n",
    "    print(model+\"\\t:\", compute_word_similarity(\n",
    "        \"./data/\" + model + \"_embedding_1E.pth\", \"私\", 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j7YfJvq5srL6",
    "outputId": "ec6656d0-9873-4769-8646-73d91dfe4887"
   },
   "outputs": [],
   "source": [
    "# 3エポック学習した時\n",
    "models = [\"cbow\", \"sg\", \"sgns\"]\n",
    "for model in models:\n",
    "    print(model+\"\\t:\", compute_word_similarity(\n",
    "        \"./data/\" + model + \"_embedding_3E.pth\", \"私\", 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ijjZxdP8stAr"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "lecture_chap1_exercise.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
