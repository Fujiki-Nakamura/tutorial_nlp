{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gBjOO4luVO6u",
    "outputId": "85508431-763f-4073-832c-e0e57b12ecc0"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aWUErmrZV1pL"
   },
   "outputs": [],
   "source": [
    "# !wget \"https://drive.google.com/uc?export=download&id=1SfrBnDt7-PrFL8zjfVap-FOPoUS6dqcT\" -O data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TTKpmxYqXoyI",
    "outputId": "21975a27-f1c5-46b2-9e3f-c2070735a5ef"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zkeVUF1RYo0R",
    "outputId": "bc4ea7f2-57de-4254-eade-2516db5cf881"
   },
   "outputs": [],
   "source": [
    "!apt-get -q -y install swig \n",
    "!apt-get install mecab\n",
    "!apt-get install libmecab-dev\n",
    "!apt-get install mecab-ipadic-utf8\n",
    "!pip install mecab-python3==0.996.5\n",
    "!pip install unidic-lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k33vOPT2aCDn"
   },
   "outputs": [],
   "source": [
    "!mkdir -p data\n",
    "!cp -r /gdrive/MyDrive/tutorial_nlp/data/* ./data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t8YJaCiimubB"
   },
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "grdhWuTtY0M6"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import time\n",
    "\n",
    "import MeCab\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "tagger = MeCab.Tagger('-Ochasen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ULrH3o9aZR3F"
   },
   "outputs": [],
   "source": [
    "def tokenize(sentence):\n",
    "    node = tagger.parse(sentence)\n",
    "    node = node.split('\\n')\n",
    "    tokenized_sentence = []\n",
    "    for i in range(len(node)):\n",
    "        feature = node[i].split('\\t')\n",
    "        if feature[0] == 'EOS':\n",
    "            break\n",
    "        tokenized_sentence.append(feature[0])\n",
    "    return tokenized_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iLiv5zb9ZsZl",
    "outputId": "57ce1281-8300-4680-db30-4f8e028d964f"
   },
   "outputs": [],
   "source": [
    "tokenize(('坊主が屏風に上手に坊主の絵を描いた'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BeWYiQBZaM_p",
    "outputId": "5e4404c7-f333-4f80-e090-ad03f8f7f7ab"
   },
   "outputs": [],
   "source": [
    "!head -5 ./data/kokoro.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uf4aUj28aRyh"
   },
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    text = []\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            line = tokenize(line)\n",
    "            text.append(line)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3hwhkBEuaar7"
   },
   "outputs": [],
   "source": [
    "text = load_data('./data/kokoro.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z2nmyZ-tao99",
    "outputId": "aaa1c0c3-c99e-4315-ed94-685bb778596e"
   },
   "outputs": [],
   "source": [
    "print(text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WA-vv1XNaqeZ"
   },
   "outputs": [],
   "source": [
    "PAD_TOKEN = '<PAD>'\n",
    "UNK_TOKEN = '<UNK>'\n",
    "PAD = 0\n",
    "UNK = 1\n",
    "MIN_COUNT = 1\n",
    "\n",
    "word2id = {\n",
    "    PAD_TOKEN: PAD,\n",
    "    UNK_TOKEN: UNK,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yk9YT-I4a6Jh"
   },
   "outputs": [],
   "source": [
    "class Vocab(object):\n",
    "    def __init__(self, word2id={}):\n",
    "        self.word2id = word2id\n",
    "        self.id2word = {id: word for word, id in word2id.items()}\n",
    "\n",
    "    def build_vocab(self, sentences, min_count=1):\n",
    "        # count words in the corpus\n",
    "        word_counter = defaultdict(int)\n",
    "        for sentence in sentences:\n",
    "            for word in sentence:\n",
    "                word_counter[word] = word_counter.get(word, 0) + 1\n",
    "\n",
    "        # add to vocabs the word whose count >= min_count\n",
    "        words = sorted([(word, count) for word, count in word_counter.items()], key=lambda x: x[1], reverse=True)\n",
    "        for word, count in words:\n",
    "            if count >= min_count:\n",
    "                _id = len(self.word2id)\n",
    "                self.word2id.setdefault(word, _id)\n",
    "                self.id2word[_id] = word\n",
    "\n",
    "        self.raw_vocab = {w: word_counter[w] for w in self.word2id if w in word_counter}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gzuzWqxgbTQ1"
   },
   "outputs": [],
   "source": [
    "vocab = Vocab(word2id)\n",
    "vocab.build_vocab(text, min_count=MIN_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UaunaodBeVFi",
    "outputId": "2e56b437-0c4e-4898-e1e0-b48070548479"
   },
   "outputs": [],
   "source": [
    "print(len(vocab.word2id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g1eUcEDseaim"
   },
   "outputs": [],
   "source": [
    "def sentence_to_ids(vocab, sen):\n",
    "    out = [vocab.word2id.get(word, UNK) for word in sen]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0aBCQyZlebUk"
   },
   "outputs": [],
   "source": [
    "id_text = [sentence_to_ids(vocab, sen) for sen in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S1KROR7OebZg",
    "outputId": "02dc0d40-ec99-4ae7-8c8e-5390f4b9f3bb"
   },
   "outputs": [],
   "source": [
    "print(text[0])\n",
    "print(id_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fayt0-eiebcD"
   },
   "outputs": [],
   "source": [
    "def pad_seq(seq, max_length):\n",
    "    \"\"\"Paddingを行う関数\n",
    "\n",
    "    :param seq: list of int, 単語のインデックスのリスト\n",
    "    :param max_length: int, バッチ内の系列の最大長\n",
    "    :return seq: list of int, 単語のインデックスのリスト\n",
    "    \"\"\"\n",
    "    seq += [PAD for _ in range(max_length - len(seq))]\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kKzhGrujohCq"
   },
   "source": [
    "### CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jQL5vw-QfCOr"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "n_batches = 500\n",
    "vocab_size = len(vocab.word2id)\n",
    "embedding_size = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RQsHGhEMfCUL"
   },
   "outputs": [],
   "source": [
    "class CBOWDataLoader(object):\n",
    "    def __init__(self, text, batch_size, window=3):\n",
    "        \"\"\"\n",
    "        :param text: list of list of int, 単語をIDに変換したデータセット\n",
    "        :param batch_size: int, ミニバッチのサイズ\n",
    "        :param window: int, 周辺単語とターゲットの単語の最大距離\n",
    "        \"\"\"\n",
    "        self.text = text\n",
    "        self.batch_size = batch_size\n",
    "        self.window = window\n",
    "        self.s_pointer = 0\n",
    "        self.max_s_pointer = len(self.text)\n",
    "        self.w_pointer = 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        batch_X, batch_Y = [], []\n",
    "\n",
    "        while len(batch_X) < self.batch_size:\n",
    "            assert len(batch_X) == len(batch_Y)\n",
    "            # 走査する対象の文\n",
    "            sen = self.text[self.s_pointer]\n",
    "            # 予測すべき単語\n",
    "            word_Y = sen[self.w_pointer]\n",
    "            # 入力となる単語群を取得\n",
    "            words_X = sen[max(0, self.w_pointer - self.window):self.w_pointer] + sen[self.w_pointer + 1:self.w_pointer + 1 + self.window]\n",
    "            words_X = pad_seq(words_X, self.window * 2)\n",
    "            batch_X.append(words_X)\n",
    "            batch_Y.append(word_Y)\n",
    "            self.w_pointer += 1\n",
    "            # 文を走査し終わったら次の文の先頭にポインタを移行する\n",
    "            # 全ての文を走査し終わったら終了する\n",
    "            if self.w_pointer >= len(sen):\n",
    "                self.s_pointer += 1\n",
    "                self.w_pointer = 0\n",
    "                if self.s_pointer >= self.max_s_pointer:\n",
    "                    self.s_pointer = 0\n",
    "                    raise StopIteration\n",
    "\n",
    "        # データはtorch.Tensorにする必要があります。dtype, deviceも指定します。\n",
    "        batch_X = torch.tensor(batch_X, dtype=torch.long, device=device)\n",
    "        batch_Y = torch.tensor(batch_Y, dtype=torch.long, device=device)\n",
    "\n",
    "        return batch_X, batch_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "43WrSjSOfsta"
   },
   "outputs": [],
   "source": [
    "class CBOW(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size):\n",
    "        \"\"\"\n",
    "        :param vocab_size: int, 語彙の総数\n",
    "        :param embedding_size: int, 単語埋め込みベクトルの次元\n",
    "        \"\"\"\n",
    "        super(CBOW, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_size = embedding_size\n",
    "\n",
    "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_size)\n",
    "        # 全結合層(バイアスなし)\n",
    "        self.linear = nn.Linear(self.embedding_size, self.vocab_size, bias=False)\n",
    "\n",
    "    def forward(self, batch_X, batch_Y):\n",
    "        \"\"\"\n",
    "        :param batch_X: torch.Tensor(dtype=torch.long), (batch_size, window*2)\n",
    "        :param batch_Y: torch.Tensor(dtype=torch.long), (batch_size,)\n",
    "        :return loss: torch.Tensor(dtype=torch.float), CBOWのloss\n",
    "        \"\"\"\n",
    "        # (batch_size, window*2, embedding_size)\n",
    "        x = self.embedding(batch_X)\n",
    "        # paddingした部分を無視するためにマスクをかけます\n",
    "        # (batch_size, window*2, embedding_size)\n",
    "        x = x * (batch_X != PAD).float().unsqueeze(-1)\n",
    "        # (batch_size, embedding_size)\n",
    "        x = x.sum(dim=1)\n",
    "        # (batch_size, vocab_size)\n",
    "        x = self.linear(x)\n",
    "        # (batch_size, vocab_size)\n",
    "        log_prob = F.log_softmax(x, dim=-1)\n",
    "        loss = F.nll_loss(log_prob, batch_Y)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d_-gOv6Yl8J6"
   },
   "source": [
    "### CBOW - Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ay36DqghjeJ6"
   },
   "outputs": [],
   "source": [
    "cbow = CBOW(vocab_size, embedding_size).to(device)\n",
    "optimizer_cbow = optim.Adam(cbow.parameters())\n",
    "dataloader_cbow = CBOWDataLoader(id_text, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OYsjudbSjeMM"
   },
   "outputs": [],
   "source": [
    "def compute_loss(model, inputs, optimizer, is_train=True):\n",
    "    \"\"\"lossを計算するための関数\n",
    "    \n",
    "    is_train=Trueならモデルをtrainモードに、\n",
    "    is_train=Falseならモデルをevaluationモードに設定します\n",
    "    \n",
    "    :param model: 学習させるモデル\n",
    "    :param input: モデルへの入力\n",
    "    :param optimizer: optimizer\n",
    "    :param is_train: bool, モデルtrainさせるか否か\n",
    "    \"\"\"\n",
    "    model.train(is_train)\n",
    "    loss = model(*inputs)\n",
    "    if is_train:\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vwKnsrKwjeOU",
    "outputId": "aa702191-a7cc-4f68-9fc5-e25c62e0ae81"
   },
   "outputs": [],
   "source": [
    "start_at = time.time()\n",
    "\n",
    "for batch_id, (batch_X, batch_Y) in enumerate(dataloader_cbow):\n",
    "    loss = compute_loss(cbow, [batch_X, batch_Y], optimizer_cbow, is_train=True)\n",
    "    if (batch_id + 1) % 100 == 0:\n",
    "        print(f'Batch {batch_id + 1} Time {time.time() - start_at:.2f} [sec] Loss {loss:.4f}')\n",
    "    if (batch_id + 1) >= n_batches:\n",
    "        break\n",
    "\n",
    "print('Training finished in {:.2f} [sec]'.format(time.time() - start_at))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r1W5bJPBpBvN"
   },
   "source": [
    "### Skipgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3YkP1qVET_Q7"
   },
   "outputs": [],
   "source": [
    "class SkipgramDataLoader(object):\n",
    "    def __init__(self, text, batch_size, window=3):\n",
    "        \"\"\"\n",
    "        :param text: list of list of int, 単語をIDに変換したデータセット\n",
    "        :param batch_size: int, ミニバッチのサイズ\n",
    "        :param window: int, 周辺単語と入力単語の最大距離\n",
    "        \"\"\"\n",
    "        self.text = text\n",
    "        self.batch_size = batch_size\n",
    "        self.window = window\n",
    "        self.w_pointer = 0\n",
    "        self.s_pointer = 0\n",
    "        self.max_s_pointer = len(self.text)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        batch_X, batch_Y = [], []\n",
    "        while len(batch_X) < self.batch_size:\n",
    "            sen = self.text[self.s_pointer]\n",
    "            # Skipgramでは入力が1単語\n",
    "            word_X = sen[self.w_pointer]\n",
    "            # 出力は周辺単語\n",
    "            words_Y = sen[max(0, self.w_pointer - self.window):self.w_pointer] + sen[self.w_pointer + 1: self.w_pointer + 1 + self.window]\n",
    "            words_Y = pad_seq(words_Y, self.window * 2)\n",
    "\n",
    "            batch_X.append(word_X)\n",
    "            batch_Y.append(words_Y)\n",
    "            self.w_pointer += 1\n",
    "\n",
    "            if self.w_pointer >= len(sen):\n",
    "                self.w_pointer = 0\n",
    "                self.s_pointer += 1\n",
    "                if self.s_pointer >= self.max_s_pointer:\n",
    "                    self.w_pointer = 0\n",
    "                    self.s_pointer = 0\n",
    "                    raise StopIteration\n",
    "\n",
    "        batch_X = torch.tensor(batch_X, dtype=torch.long, device=device)\n",
    "        batch_Y = torch.tensor(batch_Y, dtype=torch.long, device=device)\n",
    "        return batch_X, batch_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nyUuRezgT_X3"
   },
   "outputs": [],
   "source": [
    "class Skipgram(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size):\n",
    "        \"\"\"\n",
    "        :param vocab_size: int, 語彙の総数\n",
    "        :param embedding_size: int, 単語埋め込みベクトルの次元\n",
    "        \"\"\"\n",
    "        super(Skipgram, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.linear = nn.Linear(embedding_size, vocab_size)\n",
    "\n",
    "    def forward(self, batch_X, batch_Y):\n",
    "        \"\"\"\n",
    "        :param batch_X: torch.Tensor(dtype=torch.long), (batch_size,)\n",
    "        :param batch_Y: torch.Tensor(dtype=torch.long), (batch_size, window*2)\n",
    "        :return loss: torch.Tensor(dtype=torch.float), Skipgramのloss\n",
    "        \"\"\"\n",
    "        x = self.embedding(batch_X)  # (batch_size, embedding_size)\n",
    "        x = self.linear(x)  # (batch_size, vocab_size)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        x = torch.gather(input=x, dim=1, index=batch_Y)  # (batch_size, window * 2)\n",
    "        x = x * (batch_Y != PAD).float()\n",
    "        loss = x.sum(dim=1).mean().neg()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-_q533fvSCFj"
   },
   "source": [
    "### Skipgram - Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NXBue5xVnCBi",
    "outputId": "1bd7dab1-f1f8-4e6b-ec64-2ab5dcea5a1f"
   },
   "outputs": [],
   "source": [
    "sg = Skipgram(vocab_size, embedding_size).to(device)\n",
    "optimizer_sg = optim.Adam(sg.parameters())\n",
    "dataloader_sg = SkipgramDataLoader(id_text, batch_size)\n",
    "\n",
    "\n",
    "# NOTE: ひとまず train 部分のみ (validation がないため)。\n",
    "start_at = time.time()\n",
    "\n",
    "for batch_id, (batch_X, batch_Y) in enumerate(dataloader_sg):\n",
    "    sg.train()\n",
    "    loss = sg(batch_X, batch_Y)\n",
    "    optimizer_sg.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer_sg.step()\n",
    "\n",
    "    if (batch_id + 1) % 100 == 0:\n",
    "        print(f'Batch {batch_id + 1} Time {time.time() - start_at:.2f} [sec] Loss {loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dxd1cbnFakk8"
   },
   "source": [
    "### Skipgram with Negative Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sgzji90PauBV"
   },
   "outputs": [],
   "source": [
    "class SkipgramNSDataLoader(object):\n",
    "    def __init__(self, text, batch_size, window=3, n_negative=5, weights=None):\n",
    "        \"\"\"\n",
    "        :param text: list of list of int, 単語をIDに変換したデータセット\n",
    "        :param batch_size: int, ミニバッチのサイズ\n",
    "        :param window: int, 周辺単語と入力単語の最大距離\n",
    "        :param n_negative: int, 負例の数\n",
    "        :param weights: numpy.ndarray, Negative Samplingで使う確率分布\n",
    "        \"\"\"\n",
    "        self.text = text\n",
    "        self.batch_size = batch_size\n",
    "        self.window = window\n",
    "        self.n_negative = n_negative\n",
    "        if weights is not None:\n",
    "            self.weights = torch.tensor(weights).float()\n",
    "        self.w_pointer = 0\n",
    "        self.s_pointer = 0\n",
    "        self.max_s_pointer = len(self.text)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        batch_X, batch_Y, batch_N = [], [], []\n",
    "        while len(batch_X) < self.batch_size:\n",
    "            sen = self.text[self.s_pointer]\n",
    "            word_X = sen[self.w_pointer]\n",
    "            words_Y = sen[max(0, self.w_pointer - self.window):self.w_pointer] + sen[self.w_pointer + 1:self.w_pointer + 1 + self.window]\n",
    "            words_Y = pad_seq(words_Y, self.window * 2)\n",
    "            words_N = torch.multinomial(self.weights, self.n_negative).numpy().tolist()\n",
    "            batch_X.append(word_X)\n",
    "            batch_Y.append(words_Y)\n",
    "            batch_N.append(words_N)\n",
    "            self.w_pointer += 1\n",
    "\n",
    "            if self.w_pointer >= len(sen):\n",
    "                self.w_pointer = 0\n",
    "                self.s_pointer += 1\n",
    "                if self.s_pointer >= self.max_s_pointer:\n",
    "                    self.s_pointer = 0\n",
    "                    self.w_pointer = 0\n",
    "                    raise StopIteration\n",
    "\n",
    "        batch_X = torch.tensor(batch_X, dtype=torch.long, device=device)\n",
    "        batch_Y = torch.tensor(batch_Y, dtype=torch.long, device=device)\n",
    "        batch_N = torch.tensor(batch_N, dtype=torch.long, device=device)\n",
    "        return batch_X, batch_Y, batch_N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ODsufp1EauEA"
   },
   "outputs": [],
   "source": [
    "class SkipgramNS(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size):\n",
    "        \"\"\"\n",
    "        :param vocab_size: int, 語彙の総数\n",
    "        :param embedding_size: int, 単語埋め込みベクトルの次元\n",
    "        \"\"\"\n",
    "        super(SkipgramNS, self).__init__()\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.i_embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.o_embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "\n",
    "    def forward(self, batch_X, batch_Y, batch_N):\n",
    "        \"\"\"\n",
    "        :param batch_x: torch.Tensor(dtype=torch.long), (batch_size,)\n",
    "        :param batch_y: torch.Tensor(dtype=torch.long), (batch_size, window*2)\n",
    "        :param batch_n: torch.Tensor(dtype=torch.long), (batch_size, n_negative)\n",
    "        \"\"\"\n",
    "        emb_X = self.i_embedding(batch_X).unsqueeze(2)  # (batch_size, embedding_size, 1)\n",
    "        emb_Y = self.o_embedding(batch_Y)  # (batch_size, window * 2, embedding_size)\n",
    "        emb_N = self.o_embedding(batch_N)  # (batch_size, n_negative, embedding_size)\n",
    "\n",
    "        log_prob = F.logsigmoid(torch.bmm(emb_Y, emb_X).squeeze())  # (batch_size, window * 2)\n",
    "        log_prob = log_prob * (batch_Y != PAD).float()\n",
    "\n",
    "        log_prob_n = F.logsigmoid(torch.bmm(emb_N.neg(), emb_X).squeeze())  # (batch_size, n_negative)\n",
    "        \n",
    "        loss = (log_prob.sum(1) + log_prob_n.sum(1)).mean().neg()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8DjApLT0aqyR"
   },
   "source": [
    "### Skipgram with Negative Sampling - Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324
    },
    "id": "LvjSGggIfCWx",
    "outputId": "b78a1a80-06bf-43ac-8678-f15a320abb82"
   },
   "outputs": [],
   "source": [
    "sgns = SkipgramNS(vocab_size, embedding_size).to(device)\n",
    "optimizer_sgns = optim.Adam(sgns.parameters())\n",
    "\n",
    "weights = np.power([0, 0] + list(vocab.raw_vocab.values()), 3. / 4.)\n",
    "weights = weights / weights.sum()\n",
    "dataloader_sgns = SkipgramNSDataLoader(id_text, batch_size, weights=weights)\n",
    "\n",
    "sgns.train()\n",
    "start_at = time.time()\n",
    "for batch_id, (batch_X, batch_Y, batch_N) in enumerate(dataloader_sgns):\n",
    "    loss = sgns(batch_X, batch_Y, batch_N)\n",
    "    optimizer_sgns.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer_sgns.step()\n",
    "\n",
    "    if (batch_id + 1) % 100 == 0:\n",
    "        print(f'Batch {batch_id + 1} Time {time.time() - start_at:.2f} [sec] Loss {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HbEAi7UOpZmz"
   },
   "source": [
    "### Word Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fwslPauuebfD"
   },
   "outputs": [],
   "source": [
    "def compute_word_similarity(embedding_path, word, n):\n",
    "    \"\"\"\n",
    "    与えられた単語に最も似ている単語とcos類似度を返す関数\n",
    "\n",
    "    :param embedding_path: str, 保存した埋め込み層のパラメータのパス\n",
    "    :param word: str, 単語\n",
    "    :param n: int\n",
    "    :return out: str, 上位n個の類似単語とそのcos類似度\n",
    "    \"\"\"\n",
    "    embedding = torch.load(embedding_path)\n",
    "\n",
    "    # 単語ベクトルを全て単位ベクトルにする\n",
    "    norm = np.linalg.norm(embedding, ord=2, axis=1, keepdims=True)\n",
    "    norm = np.where(norm == 0, 1, norm)\n",
    "    embedding /= norm\n",
    "    e = embedding[vocab.word2id[word]]\n",
    "\n",
    "    # 単語ベクトル同士のcos類似度を計算する\n",
    "    cos_sim = np.dot(embedding, e.reshape(-1, 1)).reshape(-1, )\n",
    "    most_sim = np.argsort(cos_sim, axis=-1)[::-1][1:n+1]\n",
    "    most_sim_words = [vocab.id2word[id] for id in most_sim]\n",
    "    top_cos_sim = cos_sim[most_sim]\n",
    "    out = ', '.join([w + f'({v:.4f})' for w, v in zip(most_sim_words, top_cos_sim)])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SDR7BwzMpo8F",
    "outputId": "fb6f5302-3c35-42a3-fa77-3d9db9783b9f"
   },
   "outputs": [],
   "source": [
    "# 500バッチだけ学習した時\n",
    "models = [\"cbow\", \"sg\", \"sgns\"]\n",
    "for model in models:\n",
    "    print(model+\"\\t:\", compute_word_similarity(\n",
    "        \"./data/\" + model + \"_embedding.pth\", \"私\", 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HymV8cxxsOhg",
    "outputId": "18153513-5b4a-4456-9852-1629a7408a5c"
   },
   "outputs": [],
   "source": [
    "# 1エポック学習した時\n",
    "models = [\"cbow\", \"sg\", \"sgns\"]\n",
    "for model in models:\n",
    "    print(model+\"\\t:\", compute_word_similarity(\n",
    "        \"./data/\" + model + \"_embedding_1E.pth\", \"私\", 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j7YfJvq5srL6",
    "outputId": "ec6656d0-9873-4769-8646-73d91dfe4887"
   },
   "outputs": [],
   "source": [
    "# 3エポック学習した時\n",
    "models = [\"cbow\", \"sg\", \"sgns\"]\n",
    "for model in models:\n",
    "    print(model+\"\\t:\", compute_word_similarity(\n",
    "        \"./data/\" + model + \"_embedding_3E.pth\", \"私\", 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LBoyTDwaaz6U"
   },
   "source": [
    "### Word Analogy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ijjZxdP8stAr"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "lecture_chap1_exercise.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
